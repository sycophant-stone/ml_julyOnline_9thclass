{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第四阶段考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年8月14日至8月17日期间完成，最晚提交时间（8月17日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学将该试卷进行复制后，改名为自己姓名后，如State4Exam-WangWei.ipynb，<b>移动</b>至/0.Teacher/Exam/Stage4/目录下后，进行答题。\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:李天一\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共6题，前4题每题15分，最后两题每题20分。共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.谈谈马尔可夫模型中的无后效性思想？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "后无效性是指给定状态A，A之前的状态无法直接影响A未来的状态。\n",
    "\n",
    "马尔可夫模型一个比较显著的特点就是当前状态只依赖于另外一个状态。比如时序模型中t时刻状态只依赖t-1时刻的状态。\n",
    "隐马尔科夫模型中t观测状态只依赖t隐藏状态，t隐藏状态只依赖于t-1隐藏状态。\n",
    "\n",
    "马尔可夫的后无效性降低了模型复杂度，也降低了模型的准确度，实际表现可以接受。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.朴素贝叶斯为什么朴素？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "贝叶斯公式. $P(y\\vert x)$ 是x得到y的后验概率. $P(x\\vert y)$ y得到x的类条件概率. \n",
    "\n",
    "$P(y\\vert x)=\\frac{P(y)P(x\\vert y)}{P(x)}$\n",
    "\n",
    "主要困难在于 $P(x\\vert y)$ 是x上所有属性的联合概率,有限的样本中很难直接估计得到.\n",
    "\n",
    "朴素贝叶斯为了避开这个问题,采用了属性条件独立性假设.简单说,假设每个属性独立的对分类结果产生影响.这样公式重写为\n",
    "\n",
    "$P(y\\vert x)=\\frac{P(y)P(x\\vert y)}{P(x)}=\\frac{P(y)}{P(x)}\\prod_{i=1}^dP(x_i\\vert y)$\n",
    "\n",
    "这样根据数据集可以直接估计出 $P(c)$ 和 $P(x_i\\vert y)$,来实现贝叶斯公式.\n",
    "\n",
    "综上,为了简化计算或使计算能够成立,朴素贝叶斯使用了一个假说."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.请简要谈谈LDA主题模型的思想？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "主题模型假设文档中隐含有一系列主题,能观察到的文档的词汇的结果是由这个隐含变量参与生成的.\n",
    "\n",
    "     结果       中间过程1   中间过程2\n",
    "$P(\\mathrm{单词}\\vert\\mathrm{文档})=P(\\mathrm{单词}\\vert\\mathrm{主题})P(\\mathrm{主题}\\vert\\mathrm{文档})$\n",
    "\n",
    "LDA直译是隐含狄利克雷分布,隐说明主题变量是隐变量.狄利克雷分布是指这个算法用到了狄利克雷分布.\n",
    "\n",
    "贝叶斯学派任务先验+数据=后验.使用狄利克雷分布的主要原因是狄利克雷分布(先验)+多项分布(数据)=狄利克雷分布(后验),先验和后验分布保持一致,迭代时比较好处理.还一个原因可能是狄利克雷分布在不同参数下有形态差异较大,作为先验比较符合实际情况.\n",
    "\n",
    "LDA生成文档的过程(参数已经确定,文档如何产生)\n",
    "\n",
    "1为每个文档生成一个主题分布,总共m个文档,则有共m个主题分布,$\\theta_i$ ,i=1,2,3...m\n",
    "\n",
    "2通过 $\\theta_i$ 生成一个主题编号 $z_{i,n}$\n",
    "\n",
    "3生成基于主题的K个词汇分布 $\\varphi_k$,k=1,2,3...K\n",
    "\n",
    "4根据 $z$ 选择 $\\varphi$ 分布,产生一个词 $w_{i,n}$,这个词是第i个文档第n个词\n",
    "\n",
    "5重复以上过程,直到产生所有文档的所有词汇\n",
    "\n",
    "LDA的求解就是要根据当前文档的词汇结果估计涉及的分布的参数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.为什么说指定贝叶斯网络是Directed Acyclic Graph，为什么不能有向有环图？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "有向无环图有效表达了属性间依赖关系,使得联合概率分布计算变的简单.\n",
    "\n",
    "如果引入有向有环图,属性间依赖关系就变的复杂,联合概率无法计算."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.隐马链的后向解法是指？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "给定HMM模型, $\\lambda=(A,B,\\Pi)$ ,求解指定观测序列出现概率 $O=\\{o_1,o_2,...o_T\\}$\n",
    "\n",
    "一种是暴力求解,计算代价太高.\n",
    "\n",
    "另一种是前向后向算法.\n",
    "\n",
    "算法过程\n",
    "输入: $\\lambda=(A,B,\\Pi)$ ,$O=\\{o_1,o_2,...o_T\\}$\n",
    "\n",
    "输出: $P(O\\vert\\lambda)$\n",
    "\n",
    "1计算时刻T的隐态后向概率(T时刻序列已经生成,无论隐态是什么,后向概率都为1)\n",
    "\n",
    "$\\beta_T(i)=1,i=1,2,...N$\n",
    "\n",
    "2计算t=T-1,T-2,...1的后向概率($a_{ij}$是隐态i转到j的概率. $b_j(o_{t+1})$是隐态是j生成$o_{t+1}$观察态的概率)\n",
    "\n",
    "$\\beta_t(i)=\\sum_{j=1}^Na_{ij}b_j(o_{t+1})\\beta_{t+1}(j),i=1,2,...N$\n",
    "\n",
    "3最终结果\n",
    "\n",
    "$P(O\\vert\\lambda)$ = $\\sum_{i=1}^N\\pi_ib_i(o_1)\\beta_1(i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.请结合有向无环图DAG,简要说说你对贝叶斯网络的了解？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "贝叶斯网络是一种有向无环图,每一个节点代表一个属性,每一条有向边代表属性间的依赖关系.\n",
    "\n",
    "贝叶斯网络可视化,根据属性间的依赖关系,可以直观揭示一些数据集属性的规律.\n",
    "\n",
    "使用有向无环图可以简化联合概率的计算代价,在某些数据关系缺失的情况下,通过修改网络结构跳过相关计算.\n",
    "\n",
    "图结构的生成空间较大,使得贝叶斯网络有较高的复杂度,对于复杂任务会有更好的效果.同时,也使得找到最优网络结构成为一个很困难的任务.\n",
    "\n",
    "贝叶斯网络计算精确的后验概率是NP难的,通常借助吉布斯采样完成推断.但吉布斯采样收敛较慢,此外,存在极端概率值0或1,会导致错误."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83333333 0.16666667]\n",
      " [0.83333333 0.16666667]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.16666667])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "p=np.array([[.9,.1],[.5,.5]])#转移矩阵\n",
    "step1000=p#稳态分布\n",
    "for i in range(1000):\n",
    "    step1000=step1000.dot(p)\n",
    "print(step1000)#稳态分布\n",
    "np.array([0,1]).dot(step1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc96f319ea5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "temp.dot(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
