{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习九期第一周(机器学习基础)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年6月25日至7月2日期间完成，最晚提交时间（7月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名，即上同学姓名拼音后进行作答。格式：Week1Exam-WangWei.ipynb\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/1/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:高帅超\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请分别解释统计机器学习中的输入/输出空间，特征空间，假设空间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "输入空间：输入样本X的所有可能取值构成的集合；\n",
    "输出空间：输出标签Y的所有可能取值构成的集合；\n",
    "特征空间：将原始数据映射到的更高维的空间；\n",
    "假设空间：所有可能的函数映射构成的集合；\n",
    "参数空间：参数的所有可能取值构成的集合；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.什么是损失函数，并举例有哪些常用的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "损失函数：衡量预测值和真实值之间差异大小的函数。\n",
    "常用损失函数：01损失；平方损失（最小二乘）；对数损失（LR）；Hinge损失（SVM）；指数损失（Adaboost）；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3请结合公式进行说明结构风险最小化的含义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$R_{srm}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_{i},f(x_{i}))+\\lambda J(f)$\n",
    "    结构风险最小化是在经验误差与模型复杂度之间做出的权衡。一味的追求经验误差最小会造成模型过于复杂，进而导致\n",
    "过拟合，结构风险最小化考虑到模型复杂性的影响，在二者之间做出衡量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.谈谈什么是生成式模型与判别式模型，以及各自特点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "生成式模型：通过求联合概率进而求解出后验概率的情形。\n",
    "判别式模型：直接求解f(X)或者后验概率的情形。\n",
    "一般来讲判别式模型要简单，准确率要高于生产式模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.请解释范数，并写出L1,L2范数的定义公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "范数：强化了的距离。 L1范数是指向量中各元素绝对值之和 $||x||_{1}=\\sum_{i=1}^{n}|x_{i}|$; L2范数是指向量中各元素平方和开根号 $||x||_{2}=\\sqrt{\\sum_{i=1}^{n}x_{i}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 什么是信息熵，它的公式是？什么是信息增益?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "信息熵：关于不确定性的一种度量。 $H(X)= -\\sum_{i=1}^{n}p(x_{i})\\log{p(x_{i})}$ ;\n",
    "信息增益：变化前后信息熵的改变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 贝叶斯公式是什么？您如何理解贝叶斯思想？它与频率派有哪些区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " $P(Y|X)=\\frac{P(X|Y)P(Y)}{P(X)}$ 贝叶斯公式是将后验概率的求解转化为联合概率与先验概率的乘积。频率学派强调的是事件采样的大量重复性，趋于无穷的时候将事件的频率视为其概率，而贝叶斯则是强调抽样及其分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.请从最大似然的角度去解释逻辑回归,以及逻辑回归的损失函数是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "损失函数为对数损失 $Loss= -\\sum_{i=1}^{N}\\{y_{i}\\log(f(x_{i}))+(1-y_{i})\\log(1-f(x_{i}))\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.试析Min-Max与Z-Score这两种数据缩放各自特点，和为什么树形结构不需要做缩放？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Min-Max 线性变化，将数据映射到了[0 1],不改变原始数据的相对距离关系，但当有新数据时可能会导致最大值\n",
    "最小值发生变化；\n",
    "Z-Score则是将数据转化为符合正态分布，适用最大值最小值未知的情况；\n",
    "缩放前后并不会对顺序造成影响，不会影响树形结构的分裂位置，树形结构不涉及距离等的计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 请解释下随机森林和Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "随机森林：在bagging的基础上将基学习器固定为决策树，同时在每一次训练的过程中不是针对全部的特征，而是选择\n",
    "部分特征。\n",
    "XGBoost：在本质上仍属于Boosting的一种。在训练新模型的时候使用了梯度下降法来最小化损失函数。传统的\n",
    "boosting基学习器之间属于串行集成，存在一定的依赖关系。XGBoost实现了并行化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本周课程意见反馈(非必答)\n",
    "请同学围绕以下两点进行回答：\n",
    "- 自身总结：您自己在本周课程的学习，收获，技能掌握等方面进行总结，包括自身在哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n",
    "- 课程反馈：也可以就知识点，进度，难易度，教学方式，考试方式等等进行意见反馈，督促我们进行更有效的改进，为大家提供更优质的服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\phi \\Phi \\emptyset$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
