{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习九期第一周(机器学习基础)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年6月25日至7月2日期间完成，最晚提交时间（7月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名，即上同学姓名拼音后进行作答。格式：Week1Exam-WangWei.ipynb\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/1/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:余晗\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请分别解释统计机器学习中的输入/输出空间，特征空间，假设空间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "输入空间就是输入的参数x的可取值范围\n",
    "\n",
    "输出空间为结果y的可取值范围\n",
    "\n",
    "特征空间为原始数据根据特征的映射得到的空间\n",
    "\n",
    "假设空间为有可能满足输入到输出映射的取值空间\n",
    "\n",
    "参数空间为所有theta的取值空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.什么是损失函数，并举例有哪些常用的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "损失函数是有监督学习中,实际值和预测值误差的一种计算函数.\n",
    "常用的有逻辑回归的损失函数\n",
    "$J(\\Theta) =  \\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}-(1-logh\\Theta(x^{(i)}))-(1-y^{(i)})(1-logh\\Theta x^{(i)})$\n",
    "\n",
    "线性回归的损失函数\n",
    "\n",
    "$J(\\Theta) =  \\frac{1}{2m}\\sum_{i=1}^{m}(h\\Theta(x^{(i)}) - y^{(i)})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3请结合公式进行说明结构风险最小化的含义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$min(f\\epsilon F) = \\frac{1}{N}\\sum_{i=1}^{n}L(y_{i},f(x_{i}))+\\lambda J(f)$\n",
    "\n",
    "实际风险由经验风险(训练误差,在机器学习中可理解为损失函数)和VC维(置信范围)组成,公式中L()是损失函数,$\\lambda J(f)$是复杂度,而复杂度和VC维是成正比\n",
    "而结果风险最小化的意义就是希望在损失函数不变的情况下尽量减小学习复杂度,所以加一个$\\lambda $作为约束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.谈谈什么是生成式模型与判别式模型，以及各自特点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "判别式模型是根据样本训练得到一组权重,然后得出决策边界,新样本来了之后根据这组权重来计算判断在决策边界的哪边\n",
    "\n",
    "生成式模型则是根据数据拟合出几个分类,然后新样本来了,通过一系列的相关性算法,计算新的样本属于哪个分类\n",
    "\n",
    "特点:判别式模型反映的是各个分类本来的差异性,而生成式模型反映的是各个分类的相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.请解释范数，并写出L1,L2范数的定义公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "范数是表示向量空间里面为非零向量赋予长度的函数,比如l1为曼哈顿距离的特殊形式,l2为欧氏距离\n",
    "\n",
    "l1范数 $\\left \\| x \\right \\|_{1} = \\sum_{i=1}^{n}|x_{i}|$\n",
    "\n",
    "l2范数 $\\left \\| x \\right \\|_{2} = \\sqrt{\\sum_{i=1}^{n}x_{i}^{2}}$\n",
    "欧式距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 什么是信息熵，它的公式是？什么是信息增益?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "信息熵是对信息的不确定性的一种描述,准确说是一种信息量的期望\n",
    "\n",
    "$Ent(D) = - \\sum_{k=1}^{|y|}P_{k}log_{2}P_{k}$\n",
    "\n",
    "信息增益是特征对于判别分类作用的衡量标准,比如一个人收入高不高这个特征在判断存款上比帅不帅这个特征增益要高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 贝叶斯公式是什么？您如何理解贝叶斯思想？它与频率派有哪些区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "P(Y|X) = P(X|Y)P(Y)/P(X)\n",
    "\n",
    "贝叶斯思想是一种转换思想,它可以把一个由条件求结果的情况转化成由结果推条件\n",
    "\n",
    "比如一大堆垃圾邮件作训练,首先很容易就能得到垃圾邮件的概率P(Y),是否垃圾邮件的包含哪些词条X概率可以得到P(X|Y),\n",
    "\n",
    "词条出现的概率P(X)显然也得的出来,\n",
    "\n",
    "而新来的邮箱是否是垃圾邮箱的概率为P(Y|X),这样就很容易求出是否为垃圾邮件了\n",
    "\n",
    "区别来说\n",
    "\n",
    "贝叶斯是先求一个先验概率,可以理解为所谓的经验,然后用经验对后面的事情分类得出结果\n",
    "\n",
    "频率派就比较实在了,它们觉得先前的经验会有误差,想得出结果多干同样的事,干完然后除以干的次数就是结果了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.请从最大似然的角度去解释逻辑回归,以及逻辑回归的损失函数是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "逻辑回归的损失函数\n",
    "$J(\\Theta) =  \\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}-(1-logh\\Theta(x^{(i)}))-(1-y^{(i)})(1-logh\\Theta x^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.试析Min-Max与Z-Score这两种数据缩放各自特点，和为什么树形结构不需要做缩放？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "两者都是进行归一化的方式\n",
    "\n",
    "Min-Max是根据最大最小值的幅度进行缩放,更新了最大最小值就必须重新归一化一次,而离群数据相对比较多的时候,结果可能偏移有点大\n",
    "\n",
    "Z-Score则不会太受一些极值的影响,因为它是把数据处理为标准正态分布\n",
    "\n",
    "首先归一化的目的就是为了让梯度下降更舒服,不会因为一些特征的值特别大而影响GD的速度\n",
    "\n",
    "树不是不需要,而是不能梯度下降,也不能求导,回归树也是一刀刀切出来的,而不是用梯度下降去拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 请解释下随机森林和Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "随机森林是基于bagging对样本进行有放回随机采样,然后通过多个学习器学习出结果分类问题则采取投票机制,回归问题取均值\n",
    "Xgboost基于Cart是一个串行的过程,每棵新树的处理结果都基于之前树得到的结果,在这个基础上,Xgboost又加了正则化项和一些线性分类器使的结果更完美,就是实现有点麻烦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本周课程意见反馈(非必答)\n",
    "请同学围绕以下两点进行回答：\n",
    "- 自身总结：您自己在本周课程的学习，收获，技能掌握等方面进行总结，包括自身在哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n",
    "- 课程反馈：也可以就知识点，进度，难易度，教学方式，考试方式等等进行意见反馈，督促我们进行更有效的改进，为大家提供更优质的服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\phi \\Phi \\emptyset$最大似然没看..迟点去看一下."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
