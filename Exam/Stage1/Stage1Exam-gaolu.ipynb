{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第一阶段考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年7月4日至7月10日期间完成，最晚提交时间（7月10日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学将该试卷进行复制后，改名为自己姓名后，如State1Exam-WangWei.ipynb，<b>移动</b>至/0.Teacher/Exam/Stage1/目录下后，进行答题。\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名: gao lu\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请说明线性分类器与非线性分类器有哪些区别，具体应用场景有哪些不同？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "线性分类器：线性分类是指用一个超平面能将正负样本区分开，表达式为y=wx+b，对于二维的情况，超平面可以理解为一条直线，如一次函数。线性分类器的分类算法是基于一个线性的预测函数，决策的边界是平的，比如直线和平面。\n",
    "\n",
    "非线性分类器：分类界面没有限制，可以是一个曲面，或者是多个超平面的组合，在二维的情况下可以是一个曲线。\n",
    "\n",
    "线性分类器速度快、编程方便，但是可能拟合效果不会很好；非线性分类器编程复杂，但是效果好拟合能力强。\n",
    "\n",
    "特征比数据量还大时，选择线性分类器，因为维度高的时候，数据一般在维度空间里面会比较稀疏，很有可能线性可分。\n",
    "\n",
    "对于维度很高的特征，选择线性分类器，理由同上。\n",
    "\n",
    "对于维度极低的特征，选择非线性分类器，因为低维空间可能很多特征都跑到一起了，导致线性不可分。\n",
    "\n",
    "下面是吴恩达的见解：\n",
    "1. 如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM\n",
    "2. 如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel\n",
    "3. 如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.逻辑回归中为什么常常要对特征进行离散化?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 计算简单，离散化后数据表示为稀疏向量，内积乘法运算速度快，计算结果方便存储，容易扩展。\n",
    "\n",
    "2. 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。\n",
    "\n",
    "3. 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。\n",
    "\n",
    "4. 离散化后可以进行特征交叉，由M+N个变量变为M\\*N个变量，进一步引入非线性，提升表达能力。\n",
    "\n",
    "5. 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.随机森林如何处理缺失值？随机森林如何评估特征重要性？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RandomForest包里有两种补全缺失值的方法：\n",
    "\n",
    "方法一（na.roughfix）简单粗暴，对于训练集,同一个类别标签下的数据，如果是分类变量缺失，用众数补上，如果是连续型变量缺失，用中位数补。\n",
    "\n",
    "方法二（rfImpute）这个方法计算量大，至于比方法一好坏不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用proximity矩阵进行加权平均的方法补缺失值。然后迭代4-6次，这个补缺失值的思想和KNN有些类似。\n",
    "\n",
    "\n",
    "\n",
    "随机森林如何评估特征重要性：\n",
    "\n",
    "衡量变量重要性的方法有两种，Decrease GINI（基尼指数） 和 Decrease Accuracy：\n",
    "1) Decrease GINI： 对于回归问题，直接使用argmax(Var−VarLeft−VarRight)作为评判标准，即当前节点训练集的方差Var减去左节点的方差VarLeft和右节点的方差VarRight。\n",
    "2) Decrease Accuracy：对于一棵树Tb(x)，我们用OOB(out-of-bag)样本可以得到测试误差1；然后随机改变OOB样本的第j列：保持其他列不变，对第j列进行随机的上下置换，得到误差2。至此，我们可以用误差1-误差2来刻画变量j的重要性。基本思想就是，如果一个变量j足够重要，那么改变它会极大的增加测试误差；反之，如果改变它测试误差没有增大，则说明该变量不是那么的重要。\n",
    "\n",
    "来源：http://charleshm.github.io/2016/03/Random-Forest-Tricks/#fn:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 请说明梯度下降算法如何实现，以及它与牛顿法的不同？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。梯度下降法的搜索迭代示意图如下图所示：\n",
    "![](./sgd1.png) \n",
    "从上图可以看出，梯度下降法在接近最优解的区域收敛速度明显变慢，利用梯度下降法求解需要很多次的迭代。\n",
    "\n",
    "梯度下降法的缺点：\n",
    "（1）靠近极小值时收敛速度减慢，如上图所示；\n",
    "（2）直线搜索时可能会产生一些问题；\n",
    "（3）可能会“之字形”地下降。\n",
    "\n",
    "<img src=\"./sgd2.png\" width = \"40%\" />\n",
    "\n",
    "在机器学习中，基于基本的梯度下降法发展了两种梯度下降方法，分别为随机梯度下降法和批量梯度下降法。\n",
    "\n",
    "比如对一个线性回归（Linear Logistics）模型，假设下面的h(x)是要拟合的函数，$J(\\theta)$为损失函数，$\\theta$是参数，要迭代求解的值，$\\theta$求解出来了那最终要拟合的函数h($\\theta$)就出来了。其中m是训练集的样本个数，n是特征的个数。\n",
    "\n",
    "$$ h(\\theta)=\\sum_{j=0}^n \\theta_j x_j $$\n",
    "$$ J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m (y^{(i)} - h_{\\theta}(x^{(i)}))^2 $$\n",
    "\n",
    "1) 批量梯度下降法（Batch Gradient Descent，BGD）\n",
    "\n",
    "（1）将$J(\\theta)$对$\\theta$求偏导，得到每个$\\theta$对应的的梯度：\n",
    "$$ \\frac{\\delta J(\\theta)}{\\delta \\theta_j} = -\\frac{1}{m}\\sum_{i=1}^m (y^{(i)} - h_{\\theta}(x^{(i)}))x_j^{(i)} $$\n",
    "\n",
    "（2）利用梯度下降跟新参数，参数更新方式如下：\n",
    "$$ \\theta_j^{new} = \\theta_j + \\lambda \\frac{1}{m}\\sum_{i=1}^m (y^{(i)} - h_{\\theta}(x^{(i)}))x^{(i)}_j ...(1)$$\n",
    "\n",
    "    * 优点：全局最优解；易于并行实现；\n",
    "    * 缺点：当样本数目很多时，训练过程会很慢。\n",
    "\n",
    "从上面公式可以注意到，它得到的是一个全局最优解，但是每迭代一步，都要用到训练集所有的数据，如果m很大，那么可想而知这种方法的迭代速度会相当的慢。所以，这就引入了另外一种方法——随机梯度下降。\n",
    "\n",
    "对于批量梯度下降法，样本个数m，x为n维向量，一次迭代需要把m个样本全部带入计算，迭代一次计算量为$mn^2$。\n",
    "\n",
    "2) 随机梯度下降（Stochastic Gradient Descent，SGD）\n",
    "\n",
    "它的具体思路是在更新每一参数时都使用一个样本来进行更新，也就是方程（1）中的m等于1。每一次跟新参数都用一个样本，更新很多次。如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将$\\theta$迭代到最优解了，对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次，这种更新方式计算复杂度太高。\n",
    "\n",
    "随机梯度下降每次迭代只使用一个样本，迭代一次计算量为$n^2$，当样本个数m很大的时候，随机梯度下降迭代一次的速度要远高于批量梯度下降方法。两者的关系可以这样理解：随机梯度下降方法以损失很小的一部分精确度和增加一定数量的迭代次数为代价，换取了总体的优化效率的提升。增加的迭代次数远远小于样本的数量。但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。\n",
    "\n",
    "    * 优点：训练速度快；\n",
    "    * 缺点：准确度下降，并不是全局最优；不易于并行实现。\n",
    "\n",
    "3) 小批量梯度下降法（Mini-batch Gradient Descent，简称MBGD）：\n",
    "\n",
    "它的具体思路是在更新每一参数时都使用一部分样本来进行更新，也就是方程（1）中的m的值大于1小于所有样本的数量。为了克服上面两种方法的缺点，又同时兼顾两种方法的有点。\n",
    "\n",
    "#### 梯度下降法与牛顿法的不同\n",
    "\n",
    "从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）\n",
    "\n",
    "根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。\n",
    "\n",
    "来源: http://www.cnblogs.com/maybe2030/p/4751804.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 简要谈下您理解的的机器学习领域的正则化？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "正则化的作用实际上就是防止模型过拟合，提高模型的泛化能力。正则化的种类有很多，工程中用得较多的两类正则化一个是L1正则化，另一个则是L2正则化。\n",
    "\n",
    "在监督学习中，我们要训练一个模型，使得模型能够充分拟合训练集中的样本点，也就是希望目标函数（损失函数）最小：\n",
    "$$min_{\\theta} J(\\theta) ...(1)$$\n",
    "\n",
    "但是由于实际中的训练数据量往往并不大，如果让模型完美拟合训练数据的话，很可能造成模型过拟合，从而使得模型的泛化能力较差。这一点可以从得到的模型参数向量$\\theta$的各个分量中看出，其中大部分分量的绝对值都非常大，这种现象直观表现在图上就是曲线（曲面）不光滑，凹凸不平，很复杂；相反，如果w的各个分量的绝对值都很小，在0附近，那么曲线（曲面）就会显得很平滑。很显然，在机器学习中，我们更希望拟合出的曲线（曲面）更为平滑，因为这样的曲线（曲面）是具有较好的泛化能力的。那么如何将$\\theta$各个分量的绝对值降低呢？这就要用到正则化技术了。在用正则化技术估计参数$\\theta$时，引入了我们对参数的先验认知，即我们认为参数的绝对值应该很小。\n",
    "正则化技术就是使得目标函数的值尽可能小，与此同时，要保证||w||的值也尽可能小，即：\n",
    "$$ min_{\\theta} J(\\theta) + t || \\theta||_F ...(2)$$\n",
    "\n",
    "在上式中，优化函数的目标变成了两个，$\\theta$的取值不仅要使得J($\\theta$)的值最小，也要使得||$\\theta$||的值最小。从上式我们可以看出，一方面要使得J($\\theta$)的取值最小，必然$\\theta$的绝对值会取到很大，这样模型才能完美拟合训练样本点；另一方面，当$\\theta$的绝对值很大时，||$\\theta$||的值又会变得很大，因此为了权衡，只有使得$\\theta$取值适当，才能保证上式的值取到最优。这样得到的曲线（曲面）比式（1）得到的曲线（曲面）平滑很多，因此具有泛化能力。值得注意的是，式中的t是J($\\theta$)与||$\\theta$||之间的一个trade-off，如果t过大，那么表明对模型参数$\\theta$的惩罚越狠，这样得到的模型处于欠拟合状态，如果t过小，那么表明对模型参数$\\theta$的惩罚越小，这样得到的模型处于过拟合状态，只有选择合适的t，才能使得到的模型具有很好地泛化能力。关于如何选择t的值，工程上一般采取交叉验证的方式来确定一个较合理的t。\n",
    "\n",
    "1. L2正则化\n",
    "    $$ min_{\\theta} J(\\theta) + t || \\theta||_2^2 ...(3)$$\n",
    "    式中，$||\\theta||_2$为$\\theta$的2范式，平方是为了求解的方便。我们来看看L2正则化的性质: \n",
    "    \n",
    "    1) 从式(3)中可以看出，L2正则化对于绝对值较大的权重予以很重的惩罚，对于绝对值很小的权重予以非常非常小的惩罚，当权重绝对值趋近于0时，基本不惩罚。这个性质与L2的平方项有关系，即越大的数，其平方越大，越小的数，比如小于1的数，其平方反而越小。\n",
    "    \n",
    "    2) 从贝叶斯推导的角度看，我们可以认为式(3)中的第二项为参数$\\theta$的一个均值为0的高斯先验分布，即，$\\theta\\sim N(0, b^2)$。这也符合我们对于参数$\\theta$的先验认知：$\\theta$的绝对值不是很大。\n",
    "    \n",
    "    3）从性质2可知，既然$\\theta$的先验分布服从高斯分布，那么L2正则化的作用实际上就是使得参数向量$\\theta$的大部分分量的值趋近于0，而不是等于0。这一点在处理具有共线性特征的特征集时非常重要，也是L2在这种情况下胜过L1的原因。\n",
    "    \n",
    "    4）由于式(3)是个凸函数，并且函数可微，因此$\\theta$的值具有解析解：\n",
    "    $$ \\theta = (X^T X + tI)^{-1} X^T y $$ \n",
    "    从解的解析表达式可以看出，$\\theta$的求解不需要对$X^{-1}$是否存在作任何假设，因为I为单位矩阵，因此解析式中的逆始终存在。 \n",
    "\n",
    "2. L1正则化\n",
    "    随着海量数据处理的兴起，工程上对于模型稀疏化的要求也随之出现了。这时候，L2正则化已经不能满足需求，因为它只是使得模型的参数值趋近于0，而不是等于0，这样就无法丢掉模型里的任何一个特征，因此无法做到稀疏化。这时，L1的作用随之显现。L1正则化的作用是使得大部分模型参数的值等于0，这样一来，当模型训练好后，这些权值等于0的特征可以省去，从而达到稀疏化的目的，也节省了存储的空间，因为在计算时，值为0的特征都可以不用存储了。\n",
    "    $$ min_{\\theta} J(\\theta) + t || \\theta||_1 ...(4)$$\n",
    "    式(4)为L1正则化的linear regression，也叫lasso regression。式中$||\\theta||_1$为$\\theta$的1范式，即$\\sum_{i=1}^N |\\theta^{(i)}|$。\n",
    "\n",
    "    同样，我们来看看L1正则化的性质:\n",
    "\n",
    "    1) 从(4)中可以看出，L1正则化对于所有权重予以同样的惩罚，也就是说，不管模型参数的大小，对它们都施加同等力度的惩罚，因此，较小的权重在被惩罚后，就会变成0。因此，在经过L1正则化后，大量模型参数的值变为0或趋近于0，当然也有一部分参数的值飙得很高（这一点在性质2解释）。由于大量模型参数变为0，这些参数就不会出现在最终的模型中，因此达到了稀疏化的作用，这也说明了L1正则化自带特征选择的功能，这一点十分有用。\n",
    "    \n",
    "    2) 从贝叶斯推导的角度看，我们可以认为式(4)中的第二项为参数$\\theta$的一个均值为0的拉普拉斯先验分布。从高斯概率密度函数和拉普拉斯概率密度函数的图形中可以看出，拉普拉斯概率密度函数的截尾比高斯概率密度函数的截尾更长，也就是说L1正则化更能够接受绝对值较大的参数值。\n",
    "    \n",
    "    3) 从性质2可知，既然拉普拉斯分布比高斯分布有更长的截尾，那么可以推知L1正则化的鲁棒性要好于L2正则化，也就是说，L1正则化对于绝对值较大的参数没有L2正则化那么敏感，从而能够容忍一些这样的参数留下。\n",
    "    \n",
    "    4) 由1范式的定义可知，L1正则化在任意权值为0的时候不可导，因此式（5）不能求出$\\theta$的解析解，同时，基于梯度的优化算法也无法高效地计算出$\\theta$的值，因此对于L1正则化，一般可以采取坐标下降法求解。\n",
    "\n",
    "\n",
    "3.实践中也可以采取L1+L2结合的方式，即elastic net。这种方式同时兼顾特征选择（L1）和权重衰减（L2）。其公式如下\n",
    "    $$ min_{\\theta} J(\\theta) + tp || \\theta||_1 + t(1-p)||\\theta||_2^2$$\n",
    "\n",
    "    上式中，t为正则项与$J(\\theta)$之间的trade-off系数，和之前的描述一致，p是elastic net里独有的参数，它是L1和L2之间的一个trade-off，如果p为0，那么上式退化为L2正则化，如果p为1，那么上式退化为L1正则化。所以当p取值为0到1时（不包含端点），上式兼顾了L1和L2的特点。又由于L1为1范式，L2为2范式，那么elastic net就介于1范式和2范式之间。\n",
    "\n",
    "来源https://blog.csdn.net/henryczj/article/details/40653907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 带核的SVM为什么能分类非线性问题？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "对于非线性问题,可以通过核函数将数据的维度转化成更高维度，使得数据在高维空间中线性可分,这样就可以在高维度的特征空间中学习svm。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 请举例有哪些常用核函数，以及核函数的条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Linear Kernel:\n",
    "$$ K(x,y) = x^T y $$\n",
    "\n",
    "2. Polynomial Kernel:\n",
    "$$ K(x,y) = (ax^T y +c)^d$$\n",
    "多项式核是一种非标准核函数，它非常适合于正交归一化后的数据。\n",
    "\n",
    "3. Gaussian Kernel:\n",
    "$$ K(x,y) = \\exp{(-\\frac{||x-y||^2}{2\\sigma^2})}$$\n",
    "对于数据中的噪音有着较好的抗干扰能力，其参数决定了函数的作用范围，超过了这个范围，数据的作用就“基本消失”。这个核函数的性能对于参数十分敏感。高斯核也有很多变种，如指数核，拉普拉斯核。\n",
    "\n",
    "4. Exponential Kernel\n",
    "$$ K(x,y) = \\exp{(-\\frac{||x-y||}{2\\sigma^2})}$$\n",
    "与高斯核相比，对参数的依赖性降低，但是适用范围相对狭窄。\n",
    "\n",
    "5. Laplacian Kernel:\n",
    "$$ K(x,y) = \\exp{(-\\frac{||x-y||}{\\sigma})} $$ \n",
    "等价于指数核，唯一的区别在于拉普拉斯核对于参数的敏感性降低。\n",
    "\n",
    "\n",
    "核函数的一个充分条件是Mercer定理：\n",
    "任何半正定的函数都可以作为核函数。\n",
    "所谓半正定过的函数$f(x_i,y_i)$，是指：拥有训练数据集合$(x_1, x_2, ..., x_n)$, 我们定义一个矩阵的元素$a_{ij} = f(x_i, x_j)$，这个矩阵是n\\*n的，如果这个矩阵是半正定的，那么$f(x_i,y_i)$就称为半正定函数。\n",
    "\n",
    "\n",
    "https://blog.csdn.net/wsj998689aa/article/details/47027365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.什么是偏差与方差？当你模型受到低偏差和高方差困扰时，如何解决？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "泛化误差可以分解成偏差的平方加上方差加上噪声。偏差度量了学习算法的期望预测和真实结果的偏离程度，刻画了学习算法本身的拟合能力，方差度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响，噪声表达了当前任务上任何学习算法所能达到的期望泛化误差下界，刻画了问题本身的难度。偏差和方差称为bias和variance，一般训练程度越强，偏差越小，方差越大，泛化误差一般在中间有一个最小值，如果偏差较大，方差较小，此时一般称为欠拟合，而偏差较小，方差较大称为过拟合。\n",
    "\n",
    "偏差：$bias^2(x) = (\\overline{f}(x)-y)^2$\n",
    "\n",
    "方差：$var(x) = E_D[(f(x;D)-\\overline{f}(x))^2]$\n",
    "\n",
    "其中学习算法的期望预测：$\\overline{f}(x) = E_D[f(x;D)]$\n",
    "\n",
    "解决低偏差和高方差问题的方法：bagging、简化模型、降维。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请说明熵、联合熵、条件熵、相对熵、互信息的定义（要求公式），以及您对这些定义的理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "熵（entropy）用来衡量整个系统的总体信息量：\n",
    "$$ H(X) = -\\sum_{i=1}^{n}P(X_{k}) logP(X_{k})$$ \n",
    "\n",
    "联合熵：对于服从联合分布P(x,y)的一对离散型随机变量，联合熵定义为  \n",
    "$$ H(X,Y)=\\sum_{x\\in X}\\sum_{y\\in Y}P(x,y)\\log{P(x,y)=-E[logP(X,Y)]}$$\n",
    "联合熵大于或等于这两个变量中任一个的独立熵，少于或等于独立熵的和。该不等式有且只有在和均为统计独立的时候相等。\n",
    "这表明，两个变量关联之后不确定性会增大，但是又由于相互有制约关系，不确定程度小于单独两个变量的不确定度之和。 \n",
    "\n",
    "条件熵：就是在事件X的前提下，事件Y的熵：  \n",
    "$$ H(X|Y)=\\sum_{x\\in X,y\\in Y}P(x,y)logP(X|Y)$$  \n",
    "可以看出在Y的条件下，X的不确定度是多少。\n",
    "\n",
    "相对熵（KL距离)：两个概率密度函数p(x)和q(x)之间的相对熵定义为  \n",
    "$$D(p||q)=\\sum_{x\\in X}p(x)log\\frac{p(x)}{q(x)} =E_{p}[\\log\\frac{p(x)}{q(x)}]$$  \n",
    "描述两个随机变量距离的度量也叫交叉熵。相对熵越大，两个函数差异越大；反之，相对熵越小，两个函数差异越小。\n",
    "  \n",
    "互信息：给定两个随机变量X，Y，联合密度函数为P(x,y)，其边际函数分别为p(x),q(x)，则互信息为P(x,y) 与p(x)q(x)之间的相对熵。  \n",
    "$I(X,Y) =\\sum_{x\\in X}\\sum_{y\\in Y}log\\frac{P(x,y)}{q(x)p(y)}=H(X)-H(X|Y)$    \n",
    "互信息是在了解Y的前提下，消除X的不确定度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 请简要说明您对EM算法的理解，并列举有哪些常用的采用EM 算法求解的模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在存在隐变量的问题中，不能直接通过极大似然估计求出模型中的参数，EM算法是一种解决存在隐含变量优化问题的有效方法。EM算法是期望极大(Expectation Maximization)算法的简称，EM算法是一种迭代型的算法，在每一次的迭代过程中，主要分为两步：即求期望(Expectation)步骤和最大化(Maximization)步骤。E步选择出合适的隐变量分布（一个以观测变量为前提条件的后验分布），使得参数的似然函数与其下界相等；M步极大化似然函数的下界，拟合出参数.\n",
    "\n",
    "常用的采用EM算法求解的模型包括：高斯混合模型， K−Means，混合朴素贝叶斯模型，因子分析模型等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
