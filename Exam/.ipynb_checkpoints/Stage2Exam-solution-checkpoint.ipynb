{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第二阶段考试-参考答案\n",
    "#### 参考答案说明:\n",
    "\n",
    "- 来源：来自于网络搜索，面试，题库，笔记，书籍整理，当期及往期优秀同学贡献等途径\n",
    "- 使用：该答案供参考，非唯一固定答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共5题，每题10分，共计50分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 请写出你了解的机器学习特征工程操作都有哪些，及它们的具体实现？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 特征工程\n",
    "\n",
    "- 1.数值幅度缩放:log,MinMax,Z-score\n",
    "- 2.统计结果作为新特征\n",
    "- 3.缺失值处理\n",
    "- 4.高次特征和交叉特征   \n",
    "   - 通过生成高次项特征增加维度 PolynomialFeatures专门产生多项式的，并且多项式包含的是相互影响的特征集。\n",
    "   比如：一个输入样本是２维的。形式如[a,b] ,则二阶多项式的特征集如下[1,a,b,a^2,ab,b^2]\n",
    "- 5.离散化、分箱、分桶   \n",
    "   - 等距离cut：按等间距切分 等频qcut：百分比切分\n",
    "- 6.独热向量编码\n",
    "- 7.时间日期型   \n",
    "   - 可以得到其他维度的时间特征\n",
    "- 8.组合特征\n",
    "\n",
    "\n",
    "### 特征工程实现\n",
    "\n",
    "#### 1.幅度缩放\n",
    "```\n",
    "df.Age.apply(np.log)\n",
    "sklearn:MinMaxScaler\n",
    "sklearn:StandardScaler\n",
    "```\n",
    "#### 2.统计结果作为特征：\n",
    "```\n",
    "df_train.loc[:,'FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 \n",
    "df_train.sample(10)\n",
    "```\n",
    "#### 3.缺失值处理\n",
    "```\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "```\n",
    "#### 4.高次特征和交叉特征\n",
    "```\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit_transform(df_train[['SibSp','Parch']])\n",
    "```\n",
    "#### 5.归一化\n",
    "```\n",
    "Normalizer()\n",
    "```\n",
    "#### 6.独热向量编码\n",
    "\n",
    "```\n",
    "pandas.get_dummies()\n",
    "skelarn:OneHotEncoder\n",
    "```\n",
    "\n",
    "#### 7.日期时间\n",
    "```\n",
    "pandas:to_datetime\n",
    "dt.month dt.dayofweek dt.dayofyear\n",
    "```\n",
    "\n",
    "#### 8.文本\n",
    "````\n",
    "sklearn:CountVectorizer\n",
    "sklearn:TfidfVectorizer\n",
    "gensim:word2vec\n",
    "````\n",
    "\n",
    "\n",
    "### 特征选择\n",
    "- 1.过滤式/Filter（较少使用） 根据每一列与target的相关性选择\n",
    "- 2.包裹式/wrapper RFE,递归去除列评估结果\n",
    "- 3.嵌入式/Embedded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 特征选择实现：\n",
    "#### 1.过滤式/Filter（较少使用）\n",
    "根据每一列与target的相关性选择\n",
    "```\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import numpy as np\n",
    "select = SelectPercentile(percentile=70)\n",
    "```\n",
    "#### 2.包裹式/wrapper\n",
    "RFE,递归去除列评估结果\n",
    "```\n",
    "from sklearn.feature_selection import RFE\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=40)\n",
    "#select = RFE(LogisticRegression(penalty=\"l1\"), n_features_to_select=40)\n",
    "```\n",
    "\n",
    "#### 3.嵌入式/Embedded\n",
    "```\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold=\"median\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.模型评估中的留一法，留出法，交叉验证分别是什么操作？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 留一法：\n",
    "就是每次只留下一个样本做测试集，其它样本做训练集，如果有k个样本，则需要训练k次，测试k次。\n",
    "\n",
    "#### 留出法：\n",
    "把D划分为两部分：训练集S和测试集T，在S上训练，在T上做测试。\n",
    "\n",
    "#### 交叉验证:\n",
    "将训练集划分为K折，取一部分作为测试集，其他K-1部分作为训练集，对训练集训练后，然后切换训练集-测试集，从K-1的部分中选取一个测试机，剩下的作为训练集，然后在训练模型，这样循环完毕K折，得到的结果求平均。\n",
    "\n",
    "#### 步骤：\n",
    "1、 将全部训练集 S分成 k个不相交的子集，假设 S中的训练样例个数为 m，那么每一个子 集有 m/k 个训练样例，，相应的子集称作 {s1,s2,…,sk}。   \n",
    "2、每次从分好的子集中里面，拿出一个作为测试集，其它k-1个作为训练集   \n",
    "3、根据训练训练出模型或者假设函数。   \n",
    "4、 把这个模型放到测试集上，得到分类率。   \n",
    "5、计算k次求得的分类率的平均值，作为该模型或者假设函数的真实分类率。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.网格搜索交叉验证的作用是什么，并简述网格搜索交叉验证是如何运行的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 网格搜索：   \n",
    "- 作用：是一种通过遍历给定的参数组合来优化模型表现的方法，一般用于对模型的超参数进行遍历以确定最佳的超参数\n",
    "- 如何运行：网格搜索通过将估计函数的参数的可能取值进行排列组合，列出所有可能的组合结果生成“网格”，然后遍历所有“网格”，并使用交叉验证对结果进行评估，找到最优组合,从而找到最优参数\n",
    "\n",
    "### 交叉验证:\n",
    "- 作用：假设现在已经给定了一组固定的参数，如何评价这个组超参数的好坏呢？我们应该倾向于选择某一组超参数使得模型的泛化能力最好，而评价模型的泛化能力最常见的做法就是交叉验证。\n",
    "- 如何运行：以K折交叉验证为例，首先将训练集平均切分成K个数据子集，以第1折数据子集为验证集，并以余下K-1折作为训练集训练模型(此时模型的超参数已经由上面的网格搜索给定了一组)，得到模型之后再用验证集进行评分，这样重复K次，直到每一折数据都被当作验证集进行了一次评分。最终模型的评分就是这K次评分的平均值，这个平均值就是模型在该组超参数下的表现\n",
    "\n",
    "### 综合总结：   \n",
    "- 对网格搜索中的每一组超参数组合进行交叉验证，最后评分最好的那一个模型的超参数组合就是我们要找的最佳超参数组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.工业界上模型融合有三大类方式？试简述每类方式其思想？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "### Bagging：    \n",
    "1. 给定一个大小为d训练集D  \n",
    "2. Bagging通过从D中进行可重复的均匀采样 （by sampling from D uniformly and with replacement），得到m个新的训练集Di, 每个Di的大小为n  \n",
    "3. 将得到的m个新训练集，分别进行回归或者分类，得到m个最终的结果  \n",
    "4. 由m个结果得到最终结果，对于回归：将m个结果进行平均；对于分类：将m个结果进行投票，票数多的为最终分类值  \n",
    "\n",
    "\n",
    "### Stacking：  \n",
    "1. 将训练集分成两个不相交的部分  \n",
    "2. 在第一部分的训练集上训练若干个基本学习器  \n",
    "3. 在第二部分的训练集上测试得到的基本学习器  \n",
    "4. 使用步骤3中的预测结果作为输入，将正确的响应（responses）作为输出，训练更高级别的学习器 \n",
    "\n",
    "\n",
    "### Boosting：  \n",
    "1. 在训练集上，训练一个弱分类器   \n",
    "2. 添加一个弱分类器进行分类学习   \n",
    "a. 在这个过程中,由上次的结果进行权值调整, 训练集中数据被重新加权：对错分的样本数据增加权重，对正确分类的样本数据进行降低权重（有些boosting算法会对反复被错分的样本进行降权处理，如BrownBoost和boost by majority）；   \n",
    "b. 在权值调整后的训练集上，进行弱分类器的学习训练  \n",
    "3. 迭代步骤2   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Early Stopping指的是什么？与它相关的概念有哪些？它们在实际项目中如何被运用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "用来避免训练模型时候的过拟合，即在训练模型时使用一种迭代方法，比如梯度下降。随着epoch增加，如果在测试集上发现测试误差上升，则停止训练，为了防止过拟合。\n",
    "\n",
    "其通过学习曲线验证模型状态，如果发现模型过拟合通过增加数据集、加大正则化系数、对特征进行选择、模型同和等方式进行处理\n",
    "\n",
    "这些方法可以用来更新（训练）模型，使得它可以在每次迭代中更好的拟合训练数据。训练模型直到到达一个点，这会改善（模型）在训练集之外的表现。过了这个点（最优点），在改善模型（表现的）过程中，会带来更多的错误。\n",
    "\n",
    "基于验证集的过拟合\n",
    "这种过拟合规则主要用于将原始训练数据集切分成新的训练集和验证集时。当过拟合的时候，验证集上的错误率 被用来代替错误（作为评判标准）。\n",
    "\n",
    "https://en.wikipedia.org/wiki/Early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码题(共1题，共计50分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.使用XGBoost的sklearn接口，对KaggleCredit2数据完成信用卡欺诈项目的建模及分析\n",
    "- 要求以不同参数设置xgboost运行并进行效果比对,记录，最后给出实验报告\n",
    "\n",
    "- KaggleCredit2数据文件 位于/home/ml9/0.Teacher/Data，请勿复制或移动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
