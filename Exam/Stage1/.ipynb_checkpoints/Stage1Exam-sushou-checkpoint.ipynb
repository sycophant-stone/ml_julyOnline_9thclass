{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第一阶段考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年7月4日至7月10日期间完成，最晚提交时间（7月10日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学将该试卷进行复制后，改名为自己姓名后，如State1Exam-WangWei.ipynb，<b>移动</b>至/0.Teacher/Exam/Stage1/目录下后，进行答题。\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:苏收\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请说明线性分类器与非线性分类器有哪些区别，具体应用场景有哪些不同？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "线性分类器：模型是参数的线性函数，分界面是平面或超平面；  \n",
    "非线性分类器：模型是参数的非线性函数，分界面是曲面或者一些超平面的组合。  \n",
    "线性分类器如感知机，逻辑斯谛回归，SVM（线性核）；    \n",
    "非线性分类器如：KNN，决策树，SVM(非线性核)。  \n",
    "应用场景上，非线性分类器适合特征维度很高的场景，而线性分类器适合特征维度很低的场景。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.逻辑回归中为什么常常要对特征进行离散化?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1、 离散后产生的稀疏向量便于计算和存储。  \n",
    "2、 特征离散后，可以有效降低异常数据对计算结果的影响。比如将0~100岁的年龄，离散每个特征具有不同的权重，如果训练数据中没有出现特征（300岁），则模型中其权重为0，当测试数据出现300岁的特征时，由于权重为0，该异常数据也不会对计算结果造成影响。  \n",
    "3、 按区间进行离散化，可以增加模型稳定性。但区间划分方法也很重要。\n",
    "4、逻辑回归中单一变量离散成N个特征后，为模型引入了非线性，提升了模型的表达能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.随机森林如何处理缺失值？随机森林如何评估特征重要性？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1、 利用完整数据集，训练随机森林模型，并用来预测缺失值，如果缺失值是离散的，则采用投票的方式，如果是连续值，则采用加权平均的方式补充缺失值。  \n",
    "2、 可以采用Gini指数来评估特征的重要性，  \n",
    "Gini指数的计算公式为：  \n",
    "$ G_{m}=\\sum (1-p_{mk}^{2}) $  \n",
    "m为随机森林的当前节点，k为分类。  \n",
    "某个特征在m节点的重要性，为m节点分叉前后Gini指数的变化幅度：  \n",
    "$ VIM=G_{m} - G_{L}-G_{R} $  \n",
    "即m节点的Gini指数，减去左树枝和右树枝的Gini指数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 请说明梯度下降算法如何实现，以及它与牛顿法的不同？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "梯度下降算法：  \n",
    "在求得模型的损失函数$ J_{\\Theta} $后，对损失函数求$ \\Theta$的导数，并根据导数和超参数学习率，更新模型参数$ \\Theta $,直到得到最小值.    \n",
    "牛顿法：采用二阶泰勒级数的极值点去逼近原函数，并从上一个极值点开始下一次逼近。  \n",
    "由于计算方法的不同，在初值合理的情况牛顿法收敛速度会比较快，但二阶导数的计算难度也较大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 简要谈下您理解的的机器学习领域的正则化？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "机器学习模型中当参数较少，模型非常简单时，可能出现欠拟合，  \n",
    "预测结果与实际值偏差较大。当参数较多或参数幅度很大，  \n",
    "模型复杂时，可能出现过拟合，模型泛化能力较差。\n",
    "为了平衡模拟对训练数据的拟合效果，与模型的泛化能力，我们  \n",
    "在损失函数中加入正则化项，防止模型的参数过于复杂或参数值过大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 带核的SVM为什么能分类非线性问题？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SVM方法通过拉格朗日函数、对偶方法、KKT条件，将目标函数转换成了特征  \n",
    "向量内积的形式。\n",
    "如果另一个特征空间的向量内积，正好等价于原始特征向量的内积，则相当于  \n",
    "将原始特征向量通过映射，变换到了一个新的特征空间。\n",
    "如果这个新的特征空间是线性可分的，则可以通过引入核函数（内积）的形式  \n",
    "使得非线性问题，变得可分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 请举例有哪些常用核函数，以及核函数的条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "常用核函数：多项式核函数，高斯核函数，字符串核函数等。   \n",
    "一个函数能成为核函数的条件是：K(x，z)对应的Gram矩阵是半正定矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.什么是偏差与方差？当你模型受到低偏差和高方差困扰时，如何解决？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "偏差是指模型预测值和实际值之间的误差，偏差越大，预测值越偏离真实数据。  \n",
    "方差是指预测值得变化范围和离散程度，方差越大，数据分布越分散。   \n",
    "\n",
    "当模型偏差低、方差高时，往往是模型出现了过拟合，可以通过在损失函数  \n",
    "中加入控制参数幅度的L2正则项，来控制方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请说明熵、联合熵、条件熵、相对熵、互信息的定义（要求公式），以及您对这些定义的理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 熵\n",
    "熵是信息量的期望，反映的是一组数据的不确定性。   \n",
    "$ H(x)=-\\sum_{i=1}^{n}p(x_{i})\\log p(x_{i}) $\n",
    "#### 联合熵\n",
    "联合熵反映的是（X,Y）在一起出现时的不确定性度量。  \n",
    "$ H(x,y)=-\\sum_{i=1}^{n}\\sum_{j=1}^{n}p(x_{i},y_{i})\\log p(x_{i},y_{i}) $\n",
    "#### 条件熵\n",
    "条件熵反映的是X确定时，Y的不确定性度量，也可以说成是在X发生是前提下，Y发生新带来的熵。  \n",
    "$ H(Y|X)=--\\sum_{i=1}^{n}p(x_{i})H(Y|x_{i})\\\\\n",
    "      =-\\sum_{i=1}^{n}\\sum_{j=1}^{n}p(x_{i},y_{i})\\log \\frac{p(x_{i})}{p(x_{i},y_{i})} $\n",
    "#### 相对熵\n",
    "又称为KL散度，用于刻画两个分布之间的差异性,公式中H(p,q)指交叉熵   \n",
    "$ KL(p||q) = \\sum_{i=1}^{n}p_{i}\\log \\frac{p_{i}}{q_{i}}\\\\\n",
    "=-H(p)+H(p,q) $\n",
    "#### 互信息\n",
    "互信息用于判断特征之间的关联程度。当X,Y相互独立时，I(X,Y)=0，表示两个特征之间没有关联。    \n",
    "$  I(X,Y)=KL(p(X,Y)||P(X)P(Y))\\\\\n",
    "=\\sum_{x} \\sum_{y}P(X,Y)\\log \\frac{P(X,Y)}{P(X)P(Y)}\\\\\n",
    "=H(X) - H(X|Y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 请简要说明您对EM算法的理解，并列举有哪些常用的采用EM 算法求解的模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  在求解概率模型的时候，如果需要的变量都是观测变量，不涉及到隐藏变量的话，可以使用极大似然或者贝叶斯估计来求解模型的参数。\n",
    "  如果模型同时包含观察变量和隐藏变量的话，传统的方法不能完成模型的估计，此时就需要引入EM算法。\n",
    "  EM算法使用迭代的方法，一步步的求模型参数，使其逐渐逼近于最优，即保证本次的模型参数qi+1相比上一次的模型参数qi，使得似然函数的值变大。\n",
    "为了实现似然函数的递增，基于观察数据Y和本次的模型参数qi，构造基于未知变量q的Q(q,qi)函数，作为似然函数L的下限，Q函数最大值对应的q即为本次迭代的模型参数qi+1。\n",
    "##### 采用EM算法求解的模型有：   \n",
    "比如高斯混合模型：除了需要估计高斯模型的均值和方差，还涉及到每个高斯模型的权重信息，这个权重信息就可以认为是隐变量，所以一般使用EM来求解GMM的参数。  \n",
    "还可以用于生成模型的非监督学习，可以将输出y作为隐藏变量（未观测数据）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
