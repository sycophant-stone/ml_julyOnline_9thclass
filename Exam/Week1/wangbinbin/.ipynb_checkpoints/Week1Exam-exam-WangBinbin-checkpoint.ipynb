{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习九期第一周(机器学习基础)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年6月25日至7月2日期间完成，最晚提交时间（7月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名，即上同学姓名拼音后进行作答。格式：Week1Exam-WangWei.ipynb\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/1/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请分别解释统计机器学习中的输入/输出空间，特征空间，假设空间与参数空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入空间：所有输入可能取值的集合叫做输入空间。\n",
    "输出空间：所有输出可能取值的集合叫做输出空间。\n",
    "特征空间：具体输入（实例）的集合叫做特征空间。\n",
    "假设空间：假设空间是在已知属性和属性可能取值的情况下，对所有可能结果的假设的集合。\n",
    "参数空间：所有参数可能取值的集合叫做参数空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.什么是损失函数，并举例有哪些常用的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "损失函数：衡量模型预测值f(x）与真实值Y的不一致情况的一致程度，下面用L表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log平方损失函数：\n",
    "$$L(\\theta)=\\frac{1}{2m}\\sum_{i=0}^{n}(f(x_i)-y_i)^2$$\n",
    "对数损失函数：\n",
    "$$ L(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big[-y^{(i)}\\, log\\,( h_\\theta\\,(x^{(i)}))-(1-y^{(i)})\\,log\\,(1-h_\\theta(x^{(i)}))\\big]$$\n",
    "当然还有一些其他的损失函数，如0-1损失函数、绝对值损失函数等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3请结合公式进行说明结构风险最小化的含义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1、结构风险最小化是为了预防过拟合而提出的策略\n",
    "2、其结构可以理解为损失函数的正则化，即在损失函数后面加上正则化项或者惩罚项\n",
    "3、其中一种结构如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\theta)=\\frac{1}{2m}\\sum_{i=0}^{n}(f(x_i)-y_i)^2+\\frac{\\lambda}{2m}\\sum_{i=0}^{n}{\\theta}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.谈谈什么是生成式模型与判别式模型，以及各自特点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "生成模型：由数据学到联合概率分布，然后再求出条件分布概率的预测模型，其公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Y|X)=\\frac{P(X,Y)}{P(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "判别模型：由数据直接学习决策函数或者条件概率分布的预测模型，而不需要考虑样本的生成模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成模型特点：可以反映同类数据本身的相似度；可以还原出联合概率分布\n",
    "判别模型特点：不能反映训练数据本身的特点；反映异类数据之间的差异，不能还原联合概率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.请解释范数，并写出L1,L2范数的定义公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "广义上将：范数是向量映射到非负值的映射，其只要满足以下工时就可以称为范数："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)对于f(x)=0 一定有x=0\n",
    "2)f（x+y）<=f(x)+f(y)\n",
    "3)任意的标量a,一定有f(ax)=|a|f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1范数与L2范数是从P范数演化而来，其具体定义如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### $$L1 = \\sum_{i=1}^{n}|x_i|$$\n",
    " #### $$ L2 =\\sqrt{\\sum_{i=1}^{n}(x_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 什么是信息熵，它的公式是？什么是信息增益?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "信息熵（Entropy）可以理解为信息所携带的信息量。可以说是对信息的一种度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设$X$是一个具有有限个值的离散型随机变量，服从以下的概率分布： $P(X=x_i)=p_i, i=1,2,...,n$，则其信息熵用下面公式表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(X)=-\\sum_{i=1}^np_ilogp_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益：是指增加一种属性X后，是的H下降的程度。可以用以下的方式表达："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$G(D,A)=H(D)-H(D|A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 贝叶斯公式是什么？您如何理解贝叶斯思想？它与频率派有哪些区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "贝叶斯公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(A|B)=\\frac{P(B|A)P(A)}{\\sum_{i=1}^n{P(B|A_i)P(A_i)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们观察到的数据是“固定”的，而我们的模型的参数才是在一直变化的。我们不停地观察数据，估计出来的模型参数就可能一直的变化。不仅如此，我们对于这个模型的参数可能会有一个最初始的信仰，称之为先验假设，一旦设置后了之后，我们就可以听由观察到的数据指导模型参数更新了。\n",
    "频率学派认为：一个模型中参数是固定的二数据是分布中随机采样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.请从最大似然的角度去解释逻辑回归,以及逻辑回归的损失函数是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "逻辑回归的损失函数："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(ω)=-l(ω)=-\\sum_{i=1}^n[y^{(i)}ln(φ(z^{(i)}))+(1-y^{(i)})ln(1-φ(z^{(i)}))]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、事件发生的概率为$φ(z)$，未发生的概率为$1-φ(z)$\n",
    "2、则事件发生的概率可以等价于$φ(z^{y})*(1-φ(z))^{1-y}$\n",
    "3、既然事件已经发生，则认为整体事件发生的概率大，即单独事件的概率之乘积最大\n",
    "4、等价于J(w)最小，即等价于逻辑回归的损失函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.试析Min-Max与Z-Score这两种数据缩放各自特点，和为什么树形结构不需要做缩放？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1、Min-Max:y=(x-min)/(max-min)\n",
    "2、z-score：y=(x-u)/σ，其中u表示均值，σ表示标准差\n",
    "3、Min-Max可以消除不同数据之间的量纲，方便数据比较和共同处理；将数据映射到0-1之间方便处理；\n",
    "4、z-score标准化方法是将数据按比例缩放，使之落入一个小的特定区间。\n",
    "5、对于树型结构，数值缩放不影响分裂点位置。因为第一步都是按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 请解释下随机森林和Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1、随机森林是一个包含多个决策树的分类器，首先获取原始样本的子集（对数据、属性进行抽样），然后进行决策，最终将结果进行汇总。\n",
    "2、xgboost 是\"极端梯度上升\"(Extreme Gradient Boosting)的简称, 它类似于梯度上升框架，但是更加高效。它兼具线性模型求解器和树学习算法。因此，它快速的秘诀在于算法在单机上也可以并行计算的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本周课程意见反馈(非必答)\n",
    "请同学围绕以下两点进行回答：\n",
    "- 自身总结：您自己在本周课程的学习，收获，技能掌握等方面进行总结，包括自身在哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n",
    "- 课程反馈：也可以就知识点，进度，难易度，教学方式，考试方式等等进行意见反馈，督促我们进行更有效的改进，为大家提供更优质的服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
