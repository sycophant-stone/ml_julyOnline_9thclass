{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习九期第一周(机器学习基础)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年6月25日至7月2日期间完成，最晚提交时间（7月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名，即上同学姓名拼音后进行作答。格式：Week1Exam-WangWei.ipynb\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/1/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名: 一期一会抓紧时间\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请分别解释统计机器学习中的输入/输出空间，特征空间，假设空间与参数空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "输入空间: 输入‘X’可能取值的集合就是输入空间（input space）。\n",
    "\n",
    "输出空间: 输出‘Y’可能取值的集合就是输出空间（output space）。\n",
    "\n",
    "特征空间: 从原始数据中提取特征，将原始数据映射到一个更高维的空间，特征空间中的特征是对原始数据更高维的抽象\n",
    "    \n",
    "假设空间：机器学习中可能的函数构成的空间称为“假设空间”\n",
    "参数空间：参数可能取值的范围构成的空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.什么是损失函数，并举例有哪些常用的损失函数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "损失函数用来评价模型的预测值和真实值不一样的程度。例如：\n",
    "0-1损失函数和绝对值损失函数 \n",
    "log对数损失函数 \n",
    "平方损失函数 \n",
    "指数损失函数 \n",
    "Hinge损失函数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3请结合公式进行说明结构风险最小化的含义？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "所谓的结构风险最小化就是在保证分类精度（经验风险）的同时，降低学习机器的 VC 维，可以使学习机器在整个样本集上的期望风险得到控制。\n",
    "该思想认为，真实风险应该由两部分内容刻画，一是经验风险，代表了分类器在给定样本上的误差；\n",
    "二是置信风险，代表了在多大程度上可以信任分类器在未知文本上分类的结果。\n",
    "很显然，第二部分是没有办法精确计算的，因此只能给出一个估计的区间，\n",
    "也使得整个误差只能计算上界，而无法计算准确的值（所以叫做泛化误差界，而不叫泛化误差）。\n",
    "其中，置信风险与两个量有关，一是样本数量，显然给定的样本数量越大，学习结果越有可能正确，此时置信风险越小\n",
    "；二是分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。\n",
    "\n",
    "泛化误差界的公式为：\n",
    "\n",
    "R(w)≤Remp(w)+Ф(n/h)\n",
    "\n",
    "公式中R(w)就是真实风险，Remp(w)就是经验风险，Ф(n/h)就是置信风险。\n",
    "统计学习的目标从经验风险最小化变为了寻求经验风险与置信风险的和最小，即结构风险最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.谈谈什么是生成式模型与判别式模型，以及各自特点？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "生成式模型(generative model)会对x和y的联合分布p(x,y)进行建模,然后通过贝叶斯公式来求得p(y|x), 最后选取使得p(y|x)最大的yi. \n",
    " 判别式模型(discriminative model)则会直接对p(y|x)进行建模.\n",
    "\n",
    "生成式模型要对类条件密度(class conditional density)p(x|yi)进行建模, \n",
    "而判别式模型只需要对类后验密度(class-posterior density)进行建模, 前者通常会比后者要复杂, 更难以建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.请解释范数，并写出L1,L2范数的定义公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "范数，是具有“长度”概念的函数。在线性代数、泛函分析及相关的数学领域，范数是一个函数，是矢量空间内的所有矢量赋予非零的正长度或大小。\n",
    "半范数可以为非零的矢量赋予零长度。\n",
    "\n",
    "L1:  ||x||1 = Σ|x|\n",
    "\n",
    "L2:  ||x||2 = sqrt(Σx^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 什么是信息熵，它的公式是？什么是信息增益?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "熵（英语：entropy）是度量样本集合“纯度”最常用的一种指标。\n",
    "公式：\n",
    "Ent(D)=-Σp*log(p)\n",
    "\n",
    "信息增益以信息熵为基础，计算当前划分对信息熵所造成的变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 贝叶斯公式是什么？您如何理解贝叶斯思想？它与频率派有哪些区别？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "贝叶斯公式: P(A|B)=P(B|A)*P(A)/P(B)\n",
    "    \n",
    "贝叶斯学派并不从试图刻画「事件」本身，而从「观察者」角度出发。\n",
    "贝叶斯学派并不试图说「事件本身是随机的」，或者「世界的本体带有某种随机性」，\n",
    "而只是从「观察者知识不完备」这一出发点开始，构造一套在贝叶斯概率论的框架下可以对不确定知识做出推断的方法\n",
    "\n",
    "频率学派从「自然」角度出发，试图直接为「事件」本身建模，即事件A在独立重复试验中发生的频率趋于极限p，那么这个极限就是该事件的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.请从最大似然的角度去解释逻辑回归,以及逻辑回归的损失函数是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "最大似然估计（Maximum Likelihood Method）是建立在各样本间相互独立且样本满足随机抽样（可代表总体分布）下的估计方法，\n",
    "它的核心思想是如果现有样本可以代表总体，那么最大似然估计就是找到一组参数使得出现现有样本的可能性最大，\n",
    "即从统计学角度需要使得所有观测样本的联合概率最大化，又因为样本间是相互独立的，\n",
    "所以所有观测样本的联合概率可以写成各样本出现概率的连乘积。\n",
    "\n",
    "J(ω)=−1/m*∑[yiloghω(xi)+(1−yi)log(1−hω(xi)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.试析Min-Max与Z-Score这两种数据缩放各自特点，和为什么树形结构不需要做缩放？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min-max标准化，也称为极差法，这是对原始数据的一种线性变换，使原始数据映射到[0-1]之间。\n",
    "z-score标准化，也称为标准化分数，这种方法根据原始数据的均值和标准差进行标准化，经过处理后的数据符合标准正态分布，即均值为0，标准差为1。\n",
    "树形结构是不能进行梯度下降的，因为树模型是阶跃的，阶跃点是不可导的，并且求导没意义。所以它不需要做缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 请解释下随机森林和Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "随机森林是一种基于树模型的Bagging的优化版本。核心思想依旧是bagging，但有一些独特的改进：对训练集进行t次随机采样，在训练决策树模型的节点的时候，\n",
    "在节点所有特征中选一些样本特征。在这些特征中选择最优特征来决策树的左右子树划分。之后有决策树投票决定最终类别。\n",
    "XGBoost是一个开源软件库，为C ++，Java，Python，R和Julia提供渐变增强框架。它适用于Linux，Windows和MacOS。\n",
    "从项目描述中，它旨在提供一个“可扩展，便携式和分布式梯度提升库”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本周课程意见反馈(非必答)\n",
    "请同学围绕以下两点进行回答：\n",
    "- 自身总结：您自己在本周课程的学习，收获，技能掌握等方面进行总结，包括自身在哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n",
    "- 课程反馈：也可以就知识点，进度，难易度，教学方式，考试方式等等进行意见反馈，督促我们进行更有效的改进，为大家提供更优质的服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "从完全外行，到能懂一点ML的术语，和大概思想。老师深入简出的教学特别有效。但是我由于上课前对ML没有太多概念，练习和考试都很吃力。\n",
    "同时也觉得考试和练习就前两节课的内容来说“超纲”的有点多了。另外我虽然有python基础，但是对于numpy，pandas，sklearn类库的使用还是很陌生。\n",
    "查询API又会花不少时间。由于我是在职的，其实并没有很多时间来做练习。\n",
    "总结起来，觉得课程进度有些快，自己需要多努力才能跟上。但是反过来说，我也觉得这此课程真的超值，能学这么快其实是好消息。\n",
    "但是我也希望，如果大多数同学都感觉吃力，可以稍微慢一点。另外希望能有考试题，练习题的讲解。\n",
    "希望我能够更加努力，跟上整体课程进度。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
