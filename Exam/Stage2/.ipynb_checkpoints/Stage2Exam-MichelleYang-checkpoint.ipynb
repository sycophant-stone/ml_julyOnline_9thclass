{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第二阶段考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年7月11日至7月18日期间完成，最晚提交时间（7月18日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学将该试卷进行复制后，改名为自己姓名后，如State2Exam-WangWei.ipynb，<b>移动</b>至/0.Teacher/Exam/Stage2/目录下后，进行答题。\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:MichelleYang\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共5题，每题10分，共计50分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 请写出你了解的机器学习特征工程操作都有哪些，及它们的具体实现？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "特征工程主要是从数据中抽取出对结果预测有用的信息。特征工程主要涵盖数据采集、数据处理、特征处理、特征选择或降维等操作。\n",
    "数据采集模块中，需要考虑数据对最后结果预测的影响力，即所谓的事先考虑数据和最后预测结果的关联度；考虑数据采集的难易程度等。\n",
    "数据处理常见的操作是数据清洗以及数据采样。数据清洗主要是去除脏数据、补齐缺省值（中位数、平均数、众数补齐或者是通过模型预测）等。\n",
    "数据采样主要针对的是数据若不均衡，而有些模型对数据比较敏感，则会通过采样、SMOTE生成新数据、修改损失函数以及收集更多数据等方式来弥补。\n",
    "特征处理，数据处理后的特征针对不同的数据的类别分别进行不同的操作，针对数值型数据可以通过归一化、标准化进行幅度调整或者是将数据等频或者等距离散化。\n",
    "针对类别型数据进行one-hot编码等；针对文本型数据可以映射成稀疏向量；组合特征等一系列的特征处理操作。\n",
    "特征选择主要是一些特征冗余，可以剔除掉特征。主要方式主要有三类：filter（评估单个特征和结果的相关度）、wrapper（子集搜索）、embedding等。\n",
    "特征降维主要是对特征进行计算组合构成新的特征，例如PCA等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.模型评估中的留一法，留出法，交叉验证分别是什么操作？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "留一法主要是将N个样本分成N份，N-1个样本做训练集，1个样本做交叉验证集，总共进行N次交叉验证。\n",
    "留出法主要是将数据分为训练集和测试集，常见的训练集与训练集样本数量的比值是4:1或者是7:3.\n",
    "K折交叉验证主要是将N个训练样本分为k份，k-1份做训练，1份进行交叉验证，总共进行k次交叉验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.网格搜索交叉验证的作用是什么，并简述网格搜索交叉验证是如何运行的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "网格搜索交叉验证主要是用来通过候选集调超参数的，是微调模型的一种方法。\n",
    "网格交叉验证，正如名称一样，不同的超参数的取值进行组合，来寻找在当前候选集中最优的超参数组合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.工业界上模型融合有三大类方式？试简述每类方式其思想？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagging：采用的是一个算法，对数据进行有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合\n",
    "stacking：用多种分类器结果作为特征训练\n",
    "boosting：简单的分类器的叠加，分配给分错的样本更高的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Early Stopping指的是什么？与它相关的概念有哪些？它们在实际项目中如何被运用？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "随着epoch增加，在数据集不断进行训练，检测测试集，如果在测试集上发现测试误差上升或者不变，则停止训练，为了防止过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码题(共1题，共计50分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.使用XGBoost的sklearn接口，对KaggleCredit2数据完成信用卡欺诈项目的建模及分析\n",
    "- 要求以不同参数设置xgboost运行并进行效果比对,记录，最后给出实验报告\n",
    "\n",
    "- KaggleCredit2数据文件 位于/home/ml9/0.Teacher/Data，请勿复制或移动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:UTF-8 -*-\n",
    "# author: michelle\n",
    "# time: 2018/7/18 14:43\n",
    "# -*- coding:UTF-8 -*-\n",
    "# author: michelle\n",
    "# time: 2018/7/18 12:16\n",
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理与模型选择\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.grid_search import  GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "import itertools\n",
    "\n",
    "# 随机森林与SVM\n",
    "\n",
    "from scipy import stats\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "show_bdry = False\n",
    "show_best_c = False\n",
    "# 对所有特征做标准化处理，或者对Amount做\n",
    "def normalize_feature(data, amount_only = False):\n",
    "    if amount_only:\n",
    "        data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "    else:\n",
    "        for feature in data.columns[:-1]:\n",
    "            data[feature] = StandardScaler().fit_transform(data[feature].values.reshape(-1,1))\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_train_test(fraud_indices, normal_indices, test_size = 0.3):\n",
    "    number_records_fraud = len(fraud_indices)\n",
    "    number_records_normal = len(normal_indices)\n",
    "    test_fraud_end = int(number_records_fraud * test_size)\n",
    "    test_normal_end = int(number_records_normal  * test_size)\n",
    "\n",
    "    test_fraud_indices = fraud_indices[0:test_fraud_end]\n",
    "    train_fraud_indices = fraud_indices[test_fraud_end:]\n",
    "\n",
    "    test_normal_indices = normal_indices[0:test_normal_end]\n",
    "    train_normal_indices = normal_indices[test_normal_end:]\n",
    "\n",
    "    return train_normal_indices, train_fraud_indices, test_normal_indices, test_fraud_indices\n",
    "\n",
    "# 训练集做下采样\n",
    "def getTrainingSample(train_fraud_indices, train_normal_indices, data, train_normal_pos, ratio):\n",
    "    train_number_records_fraud = int(ratio*len(train_fraud_indices))\n",
    "    train_number_records_normal = len(train_normal_indices)\n",
    "    if train_normal_pos + train_number_records_fraud <= train_number_records_normal:\n",
    "        small_train_normal_indices = train_normal_indices[train_normal_pos: train_normal_pos + train_number_records_fraud]\n",
    "        train_normal_pos = train_normal_pos + train_number_records_fraud\n",
    "    else:\n",
    "        small_train_normal_indices = np.concatenate([train_normal_indices[train_normal_pos: train_number_records_normal],train_normal_indices[0: train_normal_pos + train_number_records_fraud- train_number_records_normal]])\n",
    "        train_normal_pos = train_normal_pos + train_number_records_fraud - train_number_records_normal\n",
    "\n",
    "    under_train_sample_indices = np.concatenate([train_fraud_indices, small_train_normal_indices])\n",
    "    np.random.shuffle(under_train_sample_indices)\n",
    "    # 下采样\n",
    "    under_train_sample_data = data.iloc[under_train_sample_indices,:]\n",
    "\n",
    "    X_train_undersample = under_train_sample_data.ix[:, under_train_sample_data.columns != 'Class']\n",
    "    y_train_undersample = under_train_sample_data.ix[:, under_train_sample_data.columns == 'Class']\n",
    "\n",
    "    return X_train_undersample, y_train_undersample, train_normal_pos\n",
    "\n",
    "def compute_recall_and_auc(y_t, y_p):\n",
    "    # 混淆矩阵\n",
    "    cnf_matrix = confusion_matrix(y_t,y_p)\n",
    "    np.set_printoptions(precision = 2)\n",
    "    recall_score = cnf_matrix[1,1]/(cnf_matrix[1,0] + cnf_matrix[1,1])\n",
    "\n",
    "    # ROC曲线与auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_t, y_p)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return recall_score, roc_auc\n",
    "\n",
    "\n",
    "def run(data, mode, ratio, iteration1):\n",
    "    for itr1 in range(iteration1):\n",
    "        #print(\"percentage: %.2f\" %(itr1/iteration1*100))\n",
    "\n",
    "        # 欺诈类的样本\n",
    "        fraud_indices = np.array(data[data.Class == 1].index)\n",
    "        np.random.shuffle(fraud_indices)\n",
    "\n",
    "        # 正常类的样本\n",
    "        normal_indices = np.array(data[data.Class == 0].index)\n",
    "        np.random.shuffle(normal_indices)\n",
    "\n",
    "        # 训练集与测试集\n",
    "        train_normal_indices, train_fraud_indices, test_normal_indices, test_fraud_indices = split_train_test(\n",
    "                                                                                            fraud_indices, normal_indices)\n",
    "        test_indices = np.concatenate([test_normal_indices,test_fraud_indices])\n",
    "\n",
    "        test_data = data.iloc[test_indices,:]\n",
    "        X_test = test_data.ix[:, test_data.columns != 'Class']\n",
    "        y_test = test_data.ix[:, test_data.columns == 'Class'].values.ravel()\n",
    "\n",
    "        # 数据下采样\n",
    "        X_train_undersample, y_train_undersample, train_normal_pos = getTrainingSample(\n",
    "                                                                    train_fraud_indices, train_normal_indices, data, 0, ratio)\n",
    "\n",
    "        # 训练模型\n",
    "        param_test1 = {\n",
    "            'max_depth': list(range(3, 10, 2)),\n",
    "            'min_child_weight': list(range(1, 6, 2))\n",
    "        }\n",
    "        model_xgb = GridSearchCV(estimator=XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                                        min_child_weight=1, gamma=0, subsample=0.8,\n",
    "                                                        colsample_bytree=0.8, objective='binary:logistic', nthread=4,\n",
    "                                                        scale_pos_weight=1, seed=27),\n",
    "                                param_grid=param_test1, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "        model_xgb.fit(X_train_undersample.values, y_train_undersample.values.ravel())\n",
    "\n",
    "        # 预测\n",
    "        y_pred = model_xgb.predict(X_test.values)\n",
    "        # 记录指标\n",
    "        recall_score, roc_auc = compute_recall_and_auc(y_test, y_pred)\n",
    "    return recall_score,roc_auc\n",
    "if __name__==\"__main__\":\n",
    "    mode = 2\n",
    "    ratio = 1\n",
    "    iteration1 = 1\n",
    "\n",
    "    data = pd.read_csv(\"./creditcard.csv\")\n",
    "    data = data.drop(['Time'], axis = 1)\n",
    "    data = normalize_feature(data, amount_only = True)\n",
    "\n",
    "    # 总体开始跑\n",
    "    result, control= run(data = data, mode = mode, ratio = ratio, iteration1 = 1)\n",
    "    print(result,control)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
