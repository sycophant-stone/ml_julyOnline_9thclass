{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第二阶段考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年7月11日至7月18日期间完成，最晚提交时间（7月18日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学将该试卷进行复制后，改名为自己姓名后，如State2Exam-WangWei.ipynb，<b>移动</b>至/0.Teacher/Exam/Stage2/目录下后，进行答题。\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:董亮\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共5题，每题10分，共计50分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 请写出你了解的机器学习特征工程操作都有哪些，及它们的具体实现？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " 1数据预处理  \n",
    "　　1.1 无量纲化  \n",
    "　　　　1.1.1 标准化  \n",
    "　　　　1.1.2 区间缩放法  \n",
    "　　　　1.1.3 标准化与归一化的区别  \n",
    "　　1.2 对定量特征二值化  \n",
    "　　1.3 对定性特征哑编码  \n",
    "　　1.4 缺失值计算  \n",
    "　　1.5 数据变换  \n",
    "2 特征选择  \n",
    "　　2.1 Filter  \n",
    "　　　　2.1.1 方差选择法  \n",
    "　　　　2.1.2 相关系数法  \n",
    "　　　　2.1.3 卡方检验  \n",
    "　　　　2.1.4 互信息法  \n",
    "　　2.2 Wrapper  \n",
    "　　　　3.2.1 递归特征消除法  \n",
    "　　2.3 Embedded  \n",
    "　　　　3.3.1 基于惩罚项的特征选择法  \n",
    "　　　　3.3.2 基于树模型的特征选择法  \n",
    "3 降维  \n",
    "　　3.1 主成分分析法（PCA）  \n",
    "　　3.2 线性判别分析法（LDA）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.模型评估中的留一法，留出法，交叉验证分别是什么操作？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "留一法  如果数据集D中有m个样本，当k=m时，则得到了交叉验证的一个特例：留一法(Leave-One-Out, LOO). \n",
    "留一法不受随机样本划分的干扰，使用的训练集比原始数据集D只少了1个样本，如此使用留一法训练的模型与使用原始数据D训练得到的模型很相似，评估结果会相对准确  \n",
    "留出法：直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，我们需要注意的是在划分的时候要尽可能保证数据分布的一致性，即避免因数据划分过程引入额外的偏差而对最终结果产生影响   \n",
    "交叉验证：k折交叉验证通常把数据集D分为k份，其中的k-1份作为训练集，剩余的那一份作为测试集，这样就可以获得k组训练/测试集，可以进行k次训练与测试，最终返回的是k个测试结果的均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.网格搜索交叉验证的作用是什么，并简述网格搜索交叉验证是如何运行的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "网格搜索法是指定参数值的一种穷举搜索方法，通过将估计函数的参数通过交叉验证的方法进行优化来得到最优的学习算法。  \n",
    "即，将各个参数可能的取值进行排列组合，列出所有可能的组合结果生成“网格”。然后将各组合用于SVM训练，并使用交叉验证对表现进行评估。在拟合函数尝试了所有的参数组合后，返回一个合适的分类器，自动调整至最佳参数组合，可以通过clf.best_params_获得参数值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.工业界上模型融合有三大类方式？试简述每类方式其思想？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bagging 用一个算法，不用全部的数据集，每次取一个子集训练一个子模型。分类用结果做vote，回归用结果做平均  用不同算法 把这些模型结果直接做平均或vote  \n",
    "Stacking 用不同算法训练模型，用测试集测出来的结果 ，训练一个新的模型，这些模型结合起来便是最终模型。  \n",
    "Boosting  训练基础算法，后续算法利用前面的算法结果重点处理错误的case，把这些stage结合起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Early Stopping指的是什么？与它相关的概念有哪些？它们在实际项目中如何被运用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "为了获得性能良好的神经网络，网络定型过程中需要进行许多关于所用设置（超参数）的决策。超参数之一是定型周期（epoch）的数量：亦即应当完整遍历数据集多少次（一次为一个epoch）？如果epoch数量太少，网络有可能发生欠拟合（即对于定型数据的学习不够充分）；如果epoch数量太多，则有可能发生过拟合（即网络对定型数据中的“噪声”而非信号拟合）。\n",
    "\n",
    "早停法旨在解决epoch数量需要手动设置的问题。它也可以被视为一种能够避免网络发生过拟合的正则化方法（与L1/L2权重衰减和丢弃法类似）。\n",
    "根本原因就是因为继续训练会导致测试集上的准确率下降。\n",
    "那继续训练导致测试准确率下降的原因猜测可能是1. 过拟合 2. 学习率过大导致不收敛  \n",
    "运用 将数据分为训练集和验证集  \n",
    "每个epoch结束后（或每N个epoch后）： 在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练；   \n",
    "将停止之后的权重作为网络的最终参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码题(共1题，共计50分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.使用XGBoost的sklearn接口，对KaggleCredit2数据完成信用卡欺诈项目的建模及分析\n",
    "- 要求以不同参数设置xgboost运行并进行效果比对,记录，最后给出实验报告\n",
    "\n",
    "- KaggleCredit2数据文件 位于/home/ml9/0.Teacher/Data，请勿复制或移动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import confusion_matrix # 引入混淆矩阵\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读文件并观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = pd.read_csv('KaggleCredit2.csv',low_memory=False)\n",
    "store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分X Y  训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = store.iloc[:,2:11]\n",
    "Y =store['SeriousDlqin2yrs']\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, Y,test_size=0.35 ,random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGBC = xgb.XGBClassifier(\n",
    "    gamma = 0.1,                      # Gamma指定了节点分裂所需的最小损失函数下降值，值越大，算法越保守。\n",
    "    learning_rate = 0.3,              # 学习速率\n",
    "    max_delta_step = 0,               # 限制每棵树权重改变的最大步长。0为没有限制，越大越保守。可用于样本不平衡的时候。\n",
    "    max_depth = 5,                    # 树的最大深度\n",
    "    min_child_weight = 6,             # 最小叶子节点样本权重和。低避免过拟合，太高导致欠拟合。\n",
    "    missing = None,                   # 如果有缺失值则替换。默认 None 就是 np.nan\n",
    "    n_estimators = 250,               # 树的数量 250/500\n",
    "    nthread = 8,                      # 并行线程数量\n",
    "    #objective = 'binary:logistic',    # 指定学习任务和相应的学习目标或要使用的自定义目标函数\n",
    "    objective='multi:softprob',    # 定义学习任务及相应的学习目标\n",
    "    #'objective':'reg:linear',        # 线性回归\n",
    "    #'objective':'reg:logistic',      # 逻辑回归\n",
    "    #'objective':'binary:logistic',   # 二分类的逻辑回归问题，输出为概率\n",
    "    #'objective':'binary:logitraw',   # 二分类的逻辑回归问题，输出结果为 wTx，wTx指机器学习线性模型f(x)=wTx+b\n",
    "    #'objective':'count:poisson'      # 计数问题的poisson回归，输出结果为poisson分布\n",
    "    #'objective':'multi:softmax'      # 让XGBoost采用softmax目标函数处理多分类问题，同时需要设置参数num_class\n",
    "    #'objective':'multi:softprob'     # 和softmax一样，但是输出的是ndata * nclass的向量，\n",
    "                                      # 可以将该向量reshape成ndata行nclass列的矩阵。\n",
    "                                      # 每行数据表示样本所属于每个类别的概率。\n",
    "    reg_alpha = 1,                    # 权重的L1正则化项。默认1\n",
    "    reg_lambda = 1,                   # 权重的L2正则化项。默认1\n",
    "    scale_pos_weight = 10000,         # 数字变大，会增加对少量诈骗样本的学习权重，这里10000比较好\n",
    "    seed = 0,                         # 随机种子\n",
    "    silent = True,                    # 静默模式开启，不会输出任何信息\n",
    "    subsample = 0.9,                  # 控制对于每棵树，随机采样的比例。减小会更加保守，避免过拟,过小会导致欠拟合。\n",
    "    base_score = 0.5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存并进行结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"精确度（Precision）：\", precision_score(test_y, preds, average='macro')) # ?? %\n",
    "print(\"召回率（Recall）：\", recall_score(test_y, preds, average='macro')) # ?? %\n",
    "predicted_y = np.array(preds)\n",
    "right_y = np.array(test_y)\n",
    "accuracy =accuracy_score(right_y,predicted_y)\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果对比  \n",
    "binary:logistic （250棵树）：精确度（Precision）： 0.5414510558174317\n",
    "召回率（Recall）： 0.6613717766259728  \n",
    "Accuracy:46.70%  \n",
    "binary:logistic （500棵树）精确度（Precision）： 0.5490908057635397\n",
    "召回率（Recall）： 0.6954519248546492  \n",
    "Accuracy:58.38%  \n",
    "binary:logistic （750棵树）精确度（Precision）： 0.5544928932993454\n",
    "召回率（Recall）： 0.7091188240266638   \n",
    "Accuracy:64.14%  \n",
    "结论  树越多 效果越好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他 ： \n",
    "gamma调高后效果反而降低  \n",
    "min_child_weight减少一点会导致效果提高\n",
    "适度减小subsample的值可以增加准确度\n",
    "目前做的对比实验不够"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
