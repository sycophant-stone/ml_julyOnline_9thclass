{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习第九期第一阶段考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年7月4日至7月10日期间完成，最晚提交时间（7月10日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学将该试卷进行复制后，改名为自己姓名后，如State1Exam-WangWei.ipynb，<b>移动</b>至/0.Teacher/Exam/Stage1/目录下后，进行答题。\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:许喆\n",
    "- 批改人：   \n",
    "- 最终得分:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问答题(共10题，每题10分，共计100分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.请说明线性分类器与非线性分类器有哪些区别，具体应用场景有哪些不同？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "线性分类器：模型是参数的线性函数，分类平面是（超）平面；\n",
    "非线性分类器：模型分界面可以是曲面或者超平面的组合。\n",
    "典型的线性分类器有感知机，LDA，逻辑斯特回归，SVM（线性核）；\n",
    "典型的非线性分类器有朴素贝叶斯，kNN，决策树，SVM（非线性核）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.逻辑回归中为什么常常要对特征进行离散化?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "在工业界，很少直接将连续值作为特征喂给逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：\n",
    "\n",
    "1.稀疏向量内积乘法运算速度快，计算结果方便存储，容易scalable（扩展）。\n",
    "2. 离散化后的特征对异常数据有很强的鲁棒性\n",
    "3. 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。\n",
    "4. 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。\n",
    "5. 特征离散化后，模型会更稳定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.随机森林如何处理缺失值？随机森林如何评估特征重要性？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "方法一（na.roughfix）对于训练集,同一个class下的数据，如果是分类变量缺失，用众数补上，如果是连续型变量缺失，用中位数补。\n",
    "方法二（rfImpute）只能补训练集中的缺失值。是先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再看缺失值，\n",
    "如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。\n",
    "如果是连续型变量，则用proximity矩阵进行加权平均的方法补缺失值。然后迭代4-5次。\n",
    "\n",
    "用随机森林进行特征重要性评估的思想其实很简单，就是看看每个特征在随机森林中的每颗树上做了多大的贡献，\n",
    "然后取个平均值，最后比一比特征之间的贡献大小。 \n",
    "通常可以用基尼指数（Gini index）或者袋外数据（OOB）错误率作为评价指标来衡量。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 请说明梯度下降算法如何实现，以及它与牛顿法的不同？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "梯度下降首先计算目标函数在当前参数值的斜率（梯度），然后乘以步长因子后带入更新公式。\n",
    "梯度下降法用目标函数的一阶偏导、以负梯度方向作为搜索方向，只考虑目标函数在迭代点的局部性质，\n",
    "牛顿法同时考虑了目标函数的一、二阶偏导数，考虑了梯度变化趋势，因而能更合适的确定搜索方向加快收敛，但牛顿法也存在以下缺点:\n",
    "1.对目标函数有严格要求，必须有连续的一、二阶偏导数，海森矩阵必须正定；\n",
    "2.计算量大，除梯度外，还需计算二阶偏导矩阵及其逆矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 简要谈下您理解的的机器学习领域的正则化？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "有几种角度来看待正则化(Regularization)，它符合奥卡姆剃刀原理：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的才是最好的模型。\n",
    "从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。\n",
    "还有个说法就是，正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项(regularizer)或惩罚项(penalty term)。\n",
    "高维统计分析模型通常都是稀疏模型，即真正有效的变量只占一小部分，绝大多数变量都是噪声数据。\n",
    "因此当模型的参数过多时，不仅无法提高模型的解释力，反而会降低模型的解释力。\n",
    "在这个背景下，统计学家提出了各种各样的变量选择方法来筛选模型中重要的解释变量，从而防止过拟合问题。\n",
    "其中正则化是最常用的一种方法，而正则化方法中最常见的就是L0, L1 和L2范数。\n",
    "正则化方法的思想：处理最优化函数问题时，在目标函数中加入对参数的约束惩罚项，从而达到简化模型的目的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 带核的SVM为什么能分类非线性问题？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "使用核函数可以将原始输入空间映射到新的特征空间，使得原始线性不可分的样本可能在核空间可分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 请举例有哪些常用核函数，以及核函数的条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "多项式核:$K(x_1, x_2)=(x_1 * x_2 + c)^{d}$\n",
    "\n",
    "高斯核:$K(x_1, x_2)=exp(-\\frac{\\gamma * ||x_1 - x_2||^2}{2\\sigma^2})$\n",
    "\n",
    "sigmoid核：$K(x_1, x_2) = tanh(\\beta*x_i^Tx_j+\\theta)$\n",
    "\n",
    "核函数必须是对称函数，核矩阵半正定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.什么是偏差与方差？当你模型受到低偏差和高方差困扰时，如何解决？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "偏差描述的是算法的预测的平均值和真实值的关系，而方差描述的是同一个算法在不同数据集上的预测值和所有数据集上的平均预测值之间的关系\n",
    "偏差可以认为是单个模型的学习能力，方差则描述的是同一个学习算法在不同数据集的不稳定性\n",
    "出现低偏差和高方差的情况时，有可能出现了过拟合，可以引入正则化，或者降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请说明熵、联合熵、条件熵、相对熵、互信息的定义（要求公式），以及您对这些定义的理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$H(X) = -\\sum_{i=1}^{n}P(X_{k}) logP(X_{k})$\n",
    "$H(X,Y) = -\\sum_{i=1}^{n}\\sum_{j=1}^{m}P(X_iY_j)logP(X_iY_j)$\n",
    "$H(X|Y) = -\\sum_{i=1}^{n}\\sum_{j=1}^{m}P(X_iY_j)logP(X_i|Y_j)$\n",
    "$D(p||q)=\\sum_{x}p(x)log\\frac{p(x)}{q(x)}$\n",
    "$I(X,Y)=\\sum_{x,y}p(x,y)log\\frac{p(x,y)}{p(x)p(y)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 请简要说明您对EM算法的理解，并列举有哪些常用的采用EM 算法求解的模型？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "常用EM算法求解的模型有k-mean, GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
